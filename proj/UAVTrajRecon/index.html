<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta content="text/html; charset=ISO-8859-1" http-equiv="content-type"><title>Flight Dynamics-based Recovery of a UAV Trajectory using Ground Cameras</title></head>
<body>
<table style="font-family: Times New Roman,Times,serif; width: 1000px; height: 900px; text-align: left; margin-left: auto; margin-right: auto;" border="0" cellpadding="20" cellspacing="0">
<tbody>
<tr>
<td colspan="2" rowspan="1"><div style="text-align: center;">
</div><h1 style="font-weight: normal; text-align: center;"><b>Flight Dynamics-based Recovery of a UAV Trajectory using Ground Cameras</b><small>
</small></h1><div style="text-align: center;">
<span style="font-size: 16pt;" lang="EN-US"><o:p></o:p></span>
<big><a href="">Artem Rozantsev</a>&nbsp;<small>1</small>&nbsp;
<a href="http://snsinha.github.io" target="_blank">Sudipta N. Sinha</a>&nbsp;<small>2</small>&nbsp;
<a href="https://www.debadeepta.com/" target="_blank">Debadeepta Dey</a>&nbsp;<small>2</small>&nbsp;
<big><a href="">Pascal Fua</a>&nbsp;<small>1</small>&nbsp;
<br><small><small><small>1</small></small></small>EPFL, Switzerland
<br><small><small><small>2</small></small></small>Microsoft Research Redmond, USA&nbsp;
<br><br>CVPR 2017<br><br></big></div>
</td>
</tr>
<tr>
<td rowspan="1" style="text-align: center;">
<!--
-->
&nbsp;
<iframe width="560" height="315" src="//www.youtube.com/embed/X8ai8tRGeNs" frameborder="0" allowfullscreen></iframe>
&nbsp;
</td>
</tr>
<tr>
<td><span style="font-weight: bold;"><font size=5>Abstract</font><br>&nbsp;<br></span>
We propose a new method to estimate the 6-dof trajectory of a ?ying object such as a 
quadrotor UAV within a 3D airspace monitored using multiple ?xed ground cameras. It 
is based on a new structure from motion formulation for the 3D reconstruction of a 
single moving point with known motion dynamics. Our main contribution is a new bundle 
adjustment procedure which in addition to optimizing the camera poses, regularizes the 
point trajectory using a prior based on motion dynamics (or speci?cally ?ight dynamics). 
Furthermore, we can infer the underlying control input sent to the UAV's autopilot that 
determined its ?ight trajectory. Our method requires neither perfect single-view tracking 
nor appearance matching across views. For robustness, we allow the tracker to generate 
multiple detections per frame in each video. The true detections and the data association 
across videos is estimated using robust multi-view triangulation and subsequently re?ned 
during our bundle adjustment procedure. Quantitative evaluation on simulated data and 
experiments on real videos from indoor and outdoor scenes demonstrates the effectiveness 
of our method.

<br><span style="font-size: 11pt; line-height: 115%;" lang="EN-US"></span></td><td style="text-align: center; width: 350px; vertical-align: middle;"> <br><br>
<img style="width: 292px;" alt="paper" src="image001.png"><br><div style="text-align: center;">
<a href="https://snsinha.github.io/pdfs/RozantsevCVPR2017.pdf" target="_blank">[PDF]</a> <a href="bibtex.txt" target="_blank">[Bibtex]</a>
<a href="https://www.youtube.com/watch?v=Z_K-KW6HAn0" [CVPR talk]</a> 
<br></div></td>
</tr>
<tr>
<td colspan=2>
<span style="font-weight: bold;"><font size=5>Dataset download</font><br>&nbsp;<br></span>
<b>About the dataset</b><br><br>
This dataset contains image sequences, AHRS data, ground truth bounding box annotations (GTBB) of a person observed from the camera onboard the MAV.<br>
We provide the following sequences used in the evaluation reported in the paper.
<br><br>
<font face="courier">
mfly-o6 &nbsp; &nbsp; &nbsp; [<a href="mfly-o6.zip">download</a>]<br>
mfly-o7  &nbsp; &nbsp; &nbsp; [<a href="mfly-o7.zip">download</a>]<br>
mfly-o8  &nbsp; &nbsp; &nbsp; [<a href="mfly-o8.zip">download</a>]<br>
mfly-o9 &nbsp; &nbsp; &nbsp; [<a href="mfly-o9.zip">download</a>]<br>
walk-i4 &nbsp; &nbsp; &nbsp; [<a href="walk-i4.zip">download</a>]<br>
walk-i5 &nbsp; &nbsp; &nbsp; [<a href="walk-i5.zip">download</a>]<br>
walk-o1  &nbsp; &nbsp; &nbsp; [<a href="walk-o1.zip">download</a>]<br>
walk-o2 &nbsp; &nbsp; &nbsp; [<a href="walk-o2.zip">download</a>]<br>
walk-o3 &nbsp; &nbsp; &nbsp; [<a href="walk-o3.zip">download</a>]<br>
</font>
<br>
<b>File format</b><br><br>
Each directory contains the following files.
<br><br>
<font face="courier">
gtbb.txt <br>
imu.txt<br>
[frame_number].png<br>
</font>
<br>
<b>Ground truth bounding box annotations</b><br><br>
Each line of the gtbb.txt file stores the 2d bounding box position -- [left, top, width, height] for each frame. Here is an example.
<br><br>
<font face="courier">
252,203,56,137<br>
</font>
<br>
This indicates that the top-left corner of the bounding box is at pixel (252,203) and the width and height of the bounding box is 56 and 137 pixels respectively.
The line number indicates the frame number.
<br><br>
<b>IMU information</b><br>
<br>
Each line of the imu.txt file contains the following information.
<br><br>
<font face="courier">
[frame number] , [time of frame captured / millisecond] , [time of IMU captured / millisecond], [roll / degree], [pitch / degree], [yaw / degree]
</font>
<br><br>
The frame number is directly associated in one-to-one fashion with the image files.
</td>
</tr>
</tbody>
</table>
<br style="font-family: Times New Roman,Times,serif;">
</body></html>
