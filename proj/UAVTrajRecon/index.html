<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta content="text/html; charset=ISO-8859-1" http-equiv="content-type"><title>Flight Dynamics-based Recovery of a UAV Trajectory using Ground Cameras</title></head>
<body>
<table style="font-family: Times New Roman,Times,serif; width: 1000px; height: 900px; text-align: left; margin-left: auto; margin-right: auto;" border="0" cellpadding="20" cellspacing="0">
<tbody>
<tr>
<td colspan="2" rowspan="1"><div style="text-align: center;">
</div><h1 style="font-weight: normal; text-align: center;"><b>Flight Dynamics-based Recovery of a UAV Trajectory using Ground Cameras</b><small>
</small></h1><div style="text-align: center;">
<span style="font-size: 16pt;" lang="EN-US"><o:p></o:p></span>
<big><a href="">Artem Rozantsev</a>&nbsp;<small>1</small>&nbsp;
<a href="http://snsinha.github.io" target="_blank">Sudipta N. Sinha</a>&nbsp;<small>2</small>&nbsp;
<a href="https://www.debadeepta.com/" target="_blank">Debadeepta Dey</a>&nbsp;<small>2</small>&nbsp;
<big><a href="">Pascal Fua</a>&nbsp;<small>1</small>&nbsp;
<br><small><small><small>1</small></small></small>EPFL, Switzerland
<br><small><small><small>2</small></small></small>Microsoft Research Redmond, USA&nbsp;
<br><br>CVPR 2017<br><br></big></div>
</td>
</tr>
<tr>
<td rowspan="1" style="text-align: center;">
<!--
-->
&nbsp;
<iframe width="560" height="315" src="//www.youtube.com/embed/udZdh0VsxvM" frameborder="0" allowfullscreen></iframe>
&nbsp;
</td>
</tr>
<tr>
<td><span style="font-weight: bold;"><font size=5>Abstract</font><br>&nbsp;<br></span>
We propose a new method to estimate the 6-dof trajectory of a ?ying object such as a 
quadrotor UAV within a 3D airspace monitored using multiple ?xed ground cameras. It 
is based on a new structure from motion formulation for the 3D reconstruction of a 
single moving point with known motion dynamics. Our main contribution is a new bundle 
adjustment procedure which in addition to optimizing the camera poses, regularizes the 
point trajectory using a prior based on motion dynamics (or speci?cally ?ight dynamics). 
Furthermore, we can infer the underlying control input sent to the UAV's autopilot that 
determined its ?ight trajectory. Our method requires neither perfect single-view tracking 
nor appearance matching across views. For robustness, we allow the tracker to generate 
multiple detections per frame in each video. The true detections and the data association 
across videos is estimated using robust multi-view triangulation and subsequently re?ned 
during our bundle adjustment procedure. Quantitative evaluation on simulated data and 
experiments on real videos from indoor and outdoor scenes demonstrates the effectiveness 
of our method.

<br><span style="font-size: 11pt; line-height: 115%;" lang="EN-US"></span></td><td style="text-align: center; width: 350px; vertical-align: middle;"> <br><br>
<img style="width: 292px;" alt="paper" src="image001.png"><br><div style="text-align: center;">
<a href="https://snsinha.github.io/pdfs/RozantsevCVPR2017.pdf" target="_blank">[PDF]</a> <a href="bibtex.txt" target="_blank">[Bibtex]</a>
<a href="https://www.youtube.com/watch?v=Z_K-KW6HAn0" [CVPR talk]</a> 
<br></div></td>
</tr>
<tr>
<td colspan=2>
<span style="font-weight: bold;"><font size=5>Dataset download</font><br>&nbsp;<br></span>

Coming Soon!</td>


</tr>
</tbody>
</table>
<br style="font-family: Times New Roman,Times,serif;">
</body></html>
